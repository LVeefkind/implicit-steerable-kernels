{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from escnn import nn, group, gspaces\n",
    "\n",
    "from models.core.point_convolution import ImplicitPointConv\n",
    "from utils.utils import get_elu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azymuthal-rotation equivariant model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement a convolutional layer that is equivariant under rotations around the z-axis and acts on field on $\\mathbb{R}^3$.\n",
    "\n",
    "Since we work in escnn, we need to specify the group space, and indicate which subgroup of O(3) we work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gspace = gspaces.rot2dOnR3() # SO(2) on R^3\n",
    "subgroup_id = gspace._sg_id[:-1] # indicator for the subgroup SO(2) \\in O(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that our input is 3 vector fields and 2 scalar fields, and the output is 1 vector field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict the standard representation of O(3) to SO(2)\n",
    "std_repr = group.o3_group().standard_representation().restrict(subgroup_id) \n",
    "triv_repr = gspace.trivial_repr \n",
    "\n",
    "in_repr = 3*[std_repr] + 2*[triv_repr]\n",
    "out_repr = 1*[std_repr] + 1*[triv_repr]\n",
    "\n",
    "# set field type of the input and output\n",
    "in_type = gspace.type(*in_repr)\n",
    "out_type = gspace.type(*out_repr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implicit point convolution takes as input node and edge features of a geometric graph.\n",
    "\n",
    "Hence, we have to specify the representation of edge features.\n",
    "\n",
    "Let us assume that we have 2 edge features,  one of which is a scalar field and one is a vector field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_repr = 1*[gspaces.no_base_space(group.o3_group()).trivial_repr] + 1*[group.o3_group().standard_representation()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[OPTIONAL] For better initialization, we can give an approximate feature distribution to the kernel.\n",
    "\n",
    "First element is for relative positions, second is for additional edge features specified above.\n",
    "\n",
    "Assuming that edge features follow a normal distribution with mean 0 and std 0.5, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_distr = [None, torch.distributions.Normal(torch.zeros(4), 0.5*torch.ones(4))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to specify the order of harmonic polynomials we use in the implicit kernel.\n",
    "\n",
    "Let's use polynomials of order 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_order = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we need to specify parameters of the MLP with which we parametrize steerable filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_params = dict(n_layers=3, \n",
    "                  n_channels=8, \n",
    "                  act_fn='elu', \n",
    "                  use_tp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now build a Steerable CNN model with 3 convolutional layers and QuotientFourier non-linearity.\n",
    "\n",
    "It is important to say that implicit kernels only support uniform representations.\n",
    "\n",
    "It means that the input and output representations of the model must be the copies of the same representation.\n",
    "\n",
    "This is not a limitatiom per se, since we can always map a non-uniform representation to a uniform one, e.g. using a Projector module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projector(nn.EquivariantModule):\n",
    "    def __init__(self, in_type: nn.FieldType, out_type: nn.FieldType):\n",
    "        super().__init__()\n",
    "        G = in_type.gspace.fibergroup\n",
    "        gspace = gspaces.no_base_space(G)\n",
    "        self.in_type = in_type\n",
    "        self.hid_type1 = gspace.type(*in_type.representations)\n",
    "        self.hid_type2 = gspace.type(*out_type.representations)\n",
    "        self.linear = nn.Linear(self.hid_type1, self.hid_type2) \n",
    "        self.out_type = out_type\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, coords = x.tensor, x.coords\n",
    "        x = self.hid_type1(x)\n",
    "        x = self.linear(x)\n",
    "        x = nn.GeometricTensor(x.tensor, self.out_type, coords)\n",
    "        return x\n",
    "    \n",
    "    def evaluate_output_shape(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 hidden fields with representation: SO(2)|[regular_[(0,)|(1,)]]:3\n"
     ]
    }
   ],
   "source": [
    "# We use 16 hidden channels for all layers and band-limit representations up to frequency L=1\n",
    "hidden_channels = 3\n",
    "L = 1\n",
    "\n",
    "activation = get_elu(gspace = in_type.gspace, L = L, channels = hidden_channels)\n",
    "\n",
    "# in Steerable CNNs, hidden channels are determined by the activation function.\n",
    "hidden_type = activation.out_type\n",
    "print(f\"{hidden_channels} hidden fields with representation: {hidden_type.representations[0]}\")\n",
    "\n",
    "proj_in = Projector(in_type, hidden_type)\n",
    "\n",
    "layer1 = ImplicitPointConv(\n",
    "    in_type=hidden_type,\n",
    "    out_type=hidden_type,\n",
    "    edge_repr=edge_repr,\n",
    "    hp_order=hp_order,\n",
    "    edge_distr=edge_distr,\n",
    "    **mlp_params)\n",
    "\n",
    "layer2 = ImplicitPointConv(\n",
    "    in_type=hidden_type,\n",
    "    out_type=hidden_type,\n",
    "    edge_repr=edge_repr,\n",
    "    hp_order=hp_order,\n",
    "    edge_distr=edge_distr,\n",
    "    **mlp_params)\n",
    "\n",
    "layer3 = ImplicitPointConv(\n",
    "    in_type=hidden_type,\n",
    "    out_type=hidden_type,\n",
    "    edge_repr=edge_repr,\n",
    "    hp_order=hp_order,\n",
    "    edge_distr=edge_distr,\n",
    "    **mlp_params)\n",
    "\n",
    "proj_out = Projector(hidden_type, out_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nn.GeometricTensor(torch.randn(10,11), in_type, torch.randn(10,3))\n",
    "edge_index = torch.randint(0, 10, (2, 20))\n",
    "edge_delta = torch.randn(20,3)\n",
    "edge_attr = torch.randn(20,4)\n",
    "\n",
    "x = proj_in(x)\n",
    "x = layer1(x=x, edge_index=edge_index, edge_delta=edge_delta, edge_attr=edge_attr, idx_downsampled=None)\n",
    "x = activation(x)\n",
    "x = layer2(x=x, edge_index=edge_index, edge_delta=edge_delta, edge_attr=edge_attr, idx_downsampled=None)\n",
    "x = activation(x)\n",
    "x = layer3(x=x, edge_index=edge_index, edge_delta=edge_delta, edge_attr=edge_attr, idx_downsampled=None)\n",
    "x = activation(x)\n",
    "x = proj_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g_tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0826, -0.1812,  0.0457, -0.6976],\n",
      "          [ 0.8479, -0.7976,  0.2348,  1.2864],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 1.8364,  0.0566, -1.8129,  2.8038],\n",
      "          [ 0.4391, -0.1789,  0.0783, -0.8419],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.2065, -0.2331,  0.2401,  0.0199]], grad_fn=<AddmmBackward0>, [SO(2)_on_R3[(False, False, -1)]: {O(3):standard (x1), irrep_0 (x1)}(4)])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test equivariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify the type of edge features for the layer (it is done automatically inside the implicit kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_type = gspaces.no_base_space(group.o3_group()).type(*[group.o3_group().standard_representation()]).restrict(subgroup_id) \n",
    "edge_type = gspaces.no_base_space(group.o3_group()).type(*edge_repr).restrict(subgroup_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_to_test = layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average absolute error for the layer: 9.29e-05\n"
     ]
    }
   ],
   "source": [
    "x = nn.GeometricTensor(torch.randn(10,hidden_type.size), layer_to_test.in_type, torch.randn(10,3))\n",
    "\n",
    "errors = []\n",
    "\n",
    "for el in gspace.testing_elements:\n",
    "    out1 = layer_to_test(x=x, edge_index=edge_index, edge_delta=edge_delta, edge_attr=edge_attr, idx_downsampled=None).transform_fibers(el).tensor.detach().numpy()\n",
    "\n",
    "    edge_delta_ = nn.GeometricTensor(edge_delta, std_type)\n",
    "    edge_attr_ = nn.GeometricTensor(edge_attr, edge_type)\n",
    "    out2 = layer_to_test(x.transform_fibers(el), \n",
    "                  edge_index=edge_index, \n",
    "                  edge_delta=edge_delta_.transform_fibers(el).tensor, \n",
    "                  edge_attr=edge_attr_.transform_fibers(el).tensor, \n",
    "                  idx_downsampled=None).tensor.detach().numpy()\n",
    "\n",
    "    errs = np.abs(out1 - out2)\n",
    "    errors.append(errs.mean())\n",
    "\n",
    "print(f\"Average absolute error for the layer: {np.mean(errors):.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The absolute error is higher that machine epsilon since we use quotient fourier nonlinearities inside of the $G$-MLP, which involves discretization and hence brings error.\n",
    "It is however gives us leverage on the degree of equivariance we want to have in our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp-pde-solvers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
